{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# getting info from sports reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_winners (link):\n",
    "    print (link)\n",
    "    page = requests.get(link)\n",
    "    #print('here')\n",
    "    soup = BS(page.content, 'html.parser')\n",
    "    idk=soup.select('div[class=\"round\"]')\n",
    "    i=0\n",
    "    k=0\n",
    "    winners=[]\n",
    "    for thing in list(range(1,100)):\n",
    "        if k == 22:\n",
    "            break\n",
    "        elif k == 0 or k== 1 or k==2 or k==3 or k==5 or k==6 or k==7 or k==8 or k==10 or k==11 or k==12 or k==13 or k==15 or k==16 or k==17 or k==18 or k==20 or k==21:\n",
    "            try:\n",
    "                winners.append(idk[k].select('div')[i].select('div[class=\"winner\"]')[0].select('span')[0].string)\n",
    "                i+=3\n",
    "            except:\n",
    "                i=0\n",
    "                k+=1\n",
    "                continue\n",
    "        else:\n",
    "            i=0\n",
    "            k+=1\n",
    "            continue\n",
    "    winners_int=[]\n",
    "    for thing in winners:\n",
    "        winners_int.append(int(thing))\n",
    "    return winners_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for getting the teams\n",
    "#gets the teams that played each other all together\n",
    "def get_teams (link,k):\n",
    "    page = requests.get(link)\n",
    "    soup = BS(page.content, 'html.parser')\n",
    "    idk=soup.select('div[class=\"round\"]')\n",
    "    i=1\n",
    "    maybe = []\n",
    "    for thing in list(range(1,100)):\n",
    "        if i%3 !=0:\n",
    "            try:\n",
    "                maybe.append(idk[k].select('div')[i].select('span')[0].string)\n",
    "                i+=1\n",
    "            except:\n",
    "                i+=1\n",
    "                continue\n",
    "        else:\n",
    "            i+=1\n",
    "            continue\n",
    "    return maybe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uses the function to split up the teams that played each other into 2 separate lists\n",
    "def split_up_teams (link):\n",
    "    All_teams = []\n",
    "    for thing in list(range(0,23)):\n",
    "        new=get_teams (link,thing)\n",
    "        All_teams.extend(new)\n",
    "    All_teams.pop(-1)\n",
    "    All_teams.pop(30)\n",
    "    All_teams.pop(60)\n",
    "    All_teams.pop(90)\n",
    "    All_teams.pop(120)\n",
    "    first_team = All_teams[0::2]\n",
    "    second_team = All_teams[1::2]\n",
    "    first_team_int = []\n",
    "    for thing in first_team:\n",
    "        first_team_int.append(int(thing))\n",
    "    second_team_int = []\n",
    "    for thing in second_team:\n",
    "        second_team_int.append(int(thing))\n",
    "    first_team_pd = pd.DataFrame(first_team_int)\n",
    "    second_team_pd = pd.DataFrame(second_team_int)\n",
    "    point_difference = first_team_pd-second_team_pd\n",
    "    point_difference_list=point_difference.values.tolist()\n",
    "    point_diff_abs = []\n",
    "    for thing in point_difference_list:\n",
    "        point_diff_abs.append(abs(thing[0]))\n",
    "    return first_team_int,second_team_int,point_diff_abs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_names (link,k):\n",
    "    page = requests.get(link)\n",
    "    soup = BS(page.content, 'html.parser')\n",
    "    idk=soup.select('div[class=\"round\"]')\n",
    "    maybe = []\n",
    "    for thing in list(range(0,100)):\n",
    "        try:\n",
    "            maybe.append(idk[k].select('a[href^=/cbb/schools]')[thing].string)\n",
    "        except:\n",
    "            continue\n",
    "    return maybe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_teams_get (link):\n",
    "    team_names = []\n",
    "    for thing in list(range(0,23)):\n",
    "        new=get_team_names (link,thing)\n",
    "        team_names.extend(new)\n",
    "    team_names.pop(-1)\n",
    "    team_names.pop(30)\n",
    "    team_names.pop(60)\n",
    "    team_names.pop(90)\n",
    "    team_names.pop(120)\n",
    "    return team_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_up_teams_2 (link):\n",
    "    All_teams = []\n",
    "    for thing in list(range(0,23)):\n",
    "        new=get_teams (link,thing)\n",
    "        All_teams.extend(new)\n",
    "    All_teams.pop(-1)\n",
    "    All_teams.pop(30)\n",
    "    All_teams.pop(60)\n",
    "    All_teams.pop(90)\n",
    "    All_teams.pop(120)\n",
    "    return All_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def everything (link):\n",
    "    first_team_int = []\n",
    "    second_team_int = []\n",
    "    point_diff_abs = []\n",
    "    winners_int = []\n",
    "\n",
    "    winners=get_winners (link)\n",
    "    three_lists=split_up_teams (link)\n",
    "    first_team_int.extend(three_lists[0])\n",
    "    second_team_int.extend(three_lists[1])\n",
    "    point_diff_abs.extend(three_lists[2])\n",
    "    winners_int.extend(winners)\n",
    "    #time.sleep(3)\n",
    "    #print(len(first_team_int), len(second_team_int),len(point_diff_abs), len(winners_int))\n",
    "    df = pd.DataFrame({\"first_team\": first_team_int, \"second_team\": second_team_int,\n",
    "                       \"winner\" : winners_int, \"point_difference\": point_diff_abs})\n",
    "    result = []\n",
    "    i = 0\n",
    "    for thing in list(df['winner']):\n",
    "        #print(f'this is {i}')\n",
    "        if list(df['first_team'])[i] > list(df['second_team'])[i] and list(df['first_team'])[i] == list(df['winner'])[i]:\n",
    "            #print(f'this is if1')\n",
    "            result.append(2)\n",
    "        elif list(df['second_team'])[i] > list(df['first_team'])[i] and list(df['second_team'])[i] == list(df['winner'])[i]:\n",
    "            #print(f'this is elif1')\n",
    "            result.append(2)\n",
    "        elif list(df['first_team'])[i] < list(df['second_team'])[i] and list(df['first_team'])[i] == list(df['winner'])[i]:\n",
    "            #print(f'this is elif2')\n",
    "            result.append(1)\n",
    "        elif list(df['second_team'])[i] < list(df['first_team'])[i] and list(df['second_team'])[i] == list(df['winner'])[i]:\n",
    "            #print(f'this is elif3')\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "        i+=1\n",
    "    df['result']=result\n",
    "    newdf2 = pd.DataFrame(np.repeat(df.values,2,axis=0))\n",
    "    newdf2.columns = df.columns\n",
    "    team_names=get_teams_get (link)\n",
    "    All_teams=split_up_teams_2(link)\n",
    "    rankings= []\n",
    "    for thing in All_teams:\n",
    "        #print(thing)\n",
    "        rankings.append(int(thing))\n",
    "    newdf2['team_name'] = team_names\n",
    "    newdf2['team_rank'] = rankings\n",
    "    win = []\n",
    "    i = 0\n",
    "    for thing in list(newdf2['team_rank']):\n",
    "        if list(newdf2['first_team'])[i] == list(newdf2['second_team'])[i]:\n",
    "            win.append(9999)\n",
    "        elif list(newdf2['team_rank'])[i] == list(newdf2['winner'])[i]:\n",
    "            win.append(1)\n",
    "        elif list(newdf2['team_rank'])[i] != list(newdf2['winner'])[i]:\n",
    "            win.append(0)\n",
    "        i+=1\n",
    "    newdf2['win']=win\n",
    "    #if the team has a lower seed number, it is given '1', higher seed number '0'\n",
    "    higher_or_lower_seed = []\n",
    "    i = 0\n",
    "    for thing in list(newdf2['team_rank']):\n",
    "        if list(newdf2['first_team'])[i] == list(newdf2['second_team'])[i]:\n",
    "            higher_or_lower_seed.append(9999)\n",
    "        elif list(newdf2['team_rank'])[i] == list(newdf2['first_team'])[i] and list(newdf2['first_team'])[i] < list(newdf2['second_team'])[i]:\n",
    "            higher_or_lower_seed.append(1)\n",
    "        elif list(newdf2['team_rank'])[i] == list(newdf2['first_team'])[i] and list(newdf2['first_team'])[i] > list(newdf2['second_team'])[i]:\n",
    "            higher_or_lower_seed.append(0)\n",
    "        elif list(newdf2['team_rank'])[i] == list(newdf2['second_team'])[i] and list(newdf2['second_team'])[i] < list(newdf2['first_team'])[i]:\n",
    "            higher_or_lower_seed.append(1)\n",
    "        elif list(newdf2['team_rank'])[i] == list(newdf2['second_team'])[i] and list(newdf2['second_team'])[i] > list(newdf2['first_team'])[i]:\n",
    "            higher_or_lower_seed.append(0)\n",
    "        i+=1\n",
    "    newdf2['higher_or_lower_seed']=higher_or_lower_seed\n",
    "    #newdf2.to_csv(f'{link}')\n",
    "    newdf2.rename(columns = {'team_name':'name'}, inplace = True)\n",
    "    newdf2['index']=list(range(0,126))\n",
    "    return newdf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# getting score info from ESPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_info (year):\n",
    "    \n",
    "    list_years = []\n",
    "    i = year\n",
    "    for num in range(0,1):\n",
    "        list_years.append(str(i))\n",
    "        i+=1\n",
    "        \n",
    "        \n",
    "    links = []\n",
    "    for thing in list_years:\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/scoring-per-game/sort/avgPoints/year/'+thing)\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/scoring-per-game/sort/avgPoints/year/'+thing+'/count/41')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/scoring-per-game/sort/avgPoints/year/'+thing+'/count/81')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/scoring-per-game/sort/avgPoints/year/'+thing+'/count/121')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/scoring-per-game/sort/avgPoints/year/'+thing+'/count/161')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/scoring-per-game/sort/avgPoints/year/'+thing+'/count/201')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/scoring-per-game/sort/avgPoints/year/'+thing+'/count/241')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/scoring-per-game/sort/avgPoints/year/'+thing+'/count/281')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/scoring-per-game/sort/avgPoints/year/'+thing+'/count/321')\n",
    "    \n",
    "    names = []\n",
    "    PTS = []\n",
    "    FG_perc = []\n",
    "    _3p_perc = []\n",
    "    FT_perc = []\n",
    "    for link in links:\n",
    "        #print(link)\n",
    "        page = requests.get(link)\n",
    "        soup = BS(page.content, 'html.parser')\n",
    "        idk=soup.select('tr[class^=\"oddrow\"]')\n",
    "        idk2=soup.select('tr[class^=\"evenrow\"]')\n",
    "        i = 0\n",
    "        if len(idk)>len(idk2):\n",
    "            for thing in idk:\n",
    "                try:    \n",
    "                    names.append(thing.select('td')[1].string)\n",
    "                    PTS.append(float(thing.select('td')[3].string))\n",
    "                    FG_perc.append(float(thing.select('td')[5].string))\n",
    "                    _3p_perc.append(float(thing.select('td')[7].string))\n",
    "                    FT_perc.append(float(thing.select('td')[9].string))\n",
    "                    \n",
    "                    names.append(idk2[i].select('td')[1].string)\n",
    "                    PTS.append(float(idk2[i].select('td')[3].string))\n",
    "                    FG_perc.append(float(idk2[i].select('td')[5].string))\n",
    "                    _3p_perc.append(float(idk2[i].select('td')[7].string))\n",
    "                    FT_perc.append(float(idk2[i].select('td')[9].string))\n",
    "                    i+=1\n",
    "                except:\n",
    "                    continue\n",
    "                    i+=1\n",
    "        else:\n",
    "            for thing in idk2:\n",
    "                try:    \n",
    "                    names.append(thing.select('td')[1].string)\n",
    "                    PTS.append(float(thing.select('td')[3].string))\n",
    "                    FG_perc.append(float(thing.select('td')[5].string))\n",
    "                    _3p_perc.append(float(thing.select('td')[7].string))\n",
    "                    FT_perc.append(float(thing.select('td')[9].string))\n",
    "                    \n",
    "                    names.append(idk[i].select('td')[1].string)\n",
    "                    PTS.append(float(idk[i].select('td')[3].string))\n",
    "                    FG_perc.append(float(idk[i].select('td')[5].string))\n",
    "                    _3p_perc.append(float(idk[i].select('td')[7].string))\n",
    "                    FT_perc.append(float(idk[i].select('td')[9].string))\n",
    "                    i+=1\n",
    "                except:\n",
    "                    continue\n",
    "                    i+=1\n",
    "    D = {'Name':names, 'PTS':PTS, 'FG_perc':FG_perc, '_3p_perc':_3p_perc, 'FT_perc':FT_perc}\n",
    "    df2 = pd.DataFrame(data=D)\n",
    "    \n",
    "    the_year = []\n",
    "    for thing in df2['Name']:\n",
    "        the_year.append(year)\n",
    "        \n",
    "    df2['year']=the_year\n",
    "            \n",
    "\n",
    "\n",
    "            \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESPN Rebound Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rebound_info (year):\n",
    "    \n",
    "    list_years = []\n",
    "    i = year\n",
    "    for num in range(0,1):\n",
    "        list_years.append(str(i))\n",
    "        i+=1\n",
    "        \n",
    "        \n",
    "    links = []\n",
    "    for thing in list_years:\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/rebounds/sort/avgPoints/year/'+thing)\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/rebounds/sort/avgPoints/year/'+thing+'/count/41')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/rebounds/sort/avgPoints/year/'+thing+'/count/81')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/rebounds/sort/avgPoints/year/'+thing+'/count/121')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/rebounds/sort/avgPoints/year/'+thing+'/count/161')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/rebounds/sort/avgPoints/year/'+thing+'/count/201')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/rebounds/sort/avgPoints/year/'+thing+'/count/241')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/rebounds/sort/avgPoints/year/'+thing+'/count/281')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/rebounds/sort/avgPoints/year/'+thing+'/count/321')\n",
    "    \n",
    "    names = []\n",
    "    ORPG = []\n",
    "    DRPG = []\n",
    "    RPG = []\n",
    "    for link in links:\n",
    "        #print(link)\n",
    "        page = requests.get(link)\n",
    "        soup = BS(page.content, 'html.parser')\n",
    "        idk=soup.select('tr[class^=\"oddrow\"]')\n",
    "        idk2=soup.select('tr[class^=\"evenrow\"]')\n",
    "        i = 0\n",
    "        if len(idk)>len(idk2):\n",
    "            for thing in idk:\n",
    "                try:    \n",
    "                    names.append(thing.select('td')[1].string)\n",
    "                    ORPG.append(float(thing.select('td')[4].string))\n",
    "                    DRPG.append(float(thing.select('td')[6].string))\n",
    "                    RPG.append(float(thing.select('td')[8].string))\n",
    "                    \n",
    "                    names.append(idk2[i].select('td')[1].string)\n",
    "                    ORPG.append(float(idk2[i].select('td')[4].string))\n",
    "                    DRPG.append(float(idk2[i].select('td')[6].string))\n",
    "                    RPG.append(float(idk2[i].select('td')[8].string))\n",
    "                    i+=1\n",
    "                except:\n",
    "                    continue\n",
    "                    i+=1\n",
    "        else:\n",
    "            for thing in idk2:\n",
    "                try:    \n",
    "                    names.append(thing.select('td')[1].string)\n",
    "                    ORPG.append(float(thing.select('td')[4].string))\n",
    "                    DRPG.append(float(thing.select('td')[6].string))\n",
    "                    RPG.append(float(thing.select('td')[8].string))\n",
    "                    \n",
    "                    names.append(idk[i].select('td')[1].string)\n",
    "                    ORPG.append(float(idk[i].select('td')[4].string))\n",
    "                    DRPG.append(float(idk[i].select('td')[6].string))\n",
    "                    RPG.append(float(idk[i].select('td')[8].string))\n",
    "                    i+=1\n",
    "                except:\n",
    "                    continue\n",
    "                    i+=1\n",
    "                    \n",
    "    D = {'Name':names, 'ORPG':ORPG, 'DRPG':DRPG, 'RPG':RPG}\n",
    "    df2 = pd.DataFrame(data=D)\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "            \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESPN Field Goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_field_goal_info (year):\n",
    "    list_years = []\n",
    "    i = year\n",
    "    for num in range(0,1):\n",
    "        list_years.append(str(i))\n",
    "        i+=1\n",
    "    \n",
    "    links = []\n",
    "    for thing in list_years:\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/field-goals/sort/avgPoints/year/'+thing)\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/field-goals/sort/avgPoints/year/'+thing+'/count/41')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/field-goals/sort/avgPoints/year/'+thing+'/count/81')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/field-goals/sort/avgPoints/year/'+thing+'/count/121')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/field-goals/sort/avgPoints/year/'+thing+'/count/161')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/field-goals/sort/avgPoints/year/'+thing+'/count/201')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/field-goals/sort/avgPoints/year/'+thing+'/count/241')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/field-goals/sort/avgPoints/year/'+thing+'/count/281')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/field-goals/sort/avgPoints/year/'+thing+'/count/321')\n",
    "        \n",
    "    names = []\n",
    "    _2pm = []\n",
    "    _2pa = []\n",
    "    _2p_perc = []\n",
    "    for link in links:\n",
    "        #print(link)\n",
    "        page = requests.get(link)\n",
    "        soup = BS(page.content, 'html.parser')\n",
    "        idk=soup.select('tr[class^=\"oddrow\"]')\n",
    "        idk2=soup.select('tr[class^=\"evenrow\"]')\n",
    "        i = 0\n",
    "        if len(idk)>len(idk2):\n",
    "            for thing in idk:\n",
    "                try:    \n",
    "                    names.append(thing.select('td')[1].string)\n",
    "                    _2pm.append(float(thing.select('td')[9].string))\n",
    "                    _2pa.append(float(thing.select('td')[10].string))\n",
    "                    _2p_perc.append(float(thing.select('td')[11].string))\n",
    "                    \n",
    "                    names.append(idk2[i].select('td')[1].string)\n",
    "                    _2pm.append(float(idk2[i].select('td')[9].string))\n",
    "                    _2pa.append(float(idk2[i].select('td')[10].string))\n",
    "                    _2p_perc.append(float(idk2[i].select('td')[11].string))\n",
    "                    i+=1\n",
    "                except:\n",
    "                    continue\n",
    "                    i+=1\n",
    "        else:\n",
    "            for thing in idk2:\n",
    "                try:    \n",
    "                    names.append(thing.select('td')[1].string)\n",
    "                    _2pm.append(float(thing.select('td')[9].string))\n",
    "                    _2pa.append(float(thing.select('td')[10].string))\n",
    "                    _2p_perc.append(float(thing.select('td')[11].string))\n",
    "                    \n",
    "                    names.append(idk[i].select('td')[1].string)\n",
    "                    _2pm.append(float(idk[i].select('td')[9].string))\n",
    "                    _2pa.append(float(idk[i].select('td')[10].string))\n",
    "                    _2p_perc.append(float(idk[i].select('td')[11].string))\n",
    "                    i+=1\n",
    "                except:\n",
    "                    continue\n",
    "                    i+=1\n",
    "            \n",
    "    D = {'Name':names, '_2pm':_2pm, '_2pa':_2pa, '_2p_perc':_2p_perc}\n",
    "    df2 = pd.DataFrame(data=D)\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "            \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESPN 3-point data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3_point_info (year):\n",
    "    \n",
    "    list_years = []\n",
    "    i = year\n",
    "    for num in range(0,1):\n",
    "        list_years.append(str(i))\n",
    "        i+=1\n",
    "        \n",
    "    \n",
    "    links = []\n",
    "    for thing in list_years:\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/3-points/sort/avgPoints/year/'+thing)\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/3-points/sort/avgPoints/year/'+thing+'/count/41')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/3-points/sort/avgPoints/year/'+thing+'/count/81')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/3-points/sort/avgPoints/year/'+thing+'/count/121')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/3-points/sort/avgPoints/year/'+thing+'/count/161')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/3-points/sort/avgPoints/year/'+thing+'/count/201')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/3-points/sort/avgPoints/year/'+thing+'/count/241')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/3-points/sort/avgPoints/year/'+thing+'/count/281')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/3-points/sort/avgPoints/year/'+thing+'/count/321')\n",
    "    \n",
    "    \n",
    "    names = []\n",
    "    _3pm = []\n",
    "    _3pa = []\n",
    "    for link in links:\n",
    "        #print(link)\n",
    "        page = requests.get(link)\n",
    "        soup = BS(page.content, 'html.parser')\n",
    "        idk=soup.select('tr[class^=\"oddrow\"]')\n",
    "        idk2=soup.select('tr[class^=\"evenrow\"]')\n",
    "        i = 0\n",
    "        if len(idk)>len(idk2):\n",
    "            for thing in idk:\n",
    "                try:    \n",
    "                    names.append(thing.select('td')[1].string)\n",
    "                    _3pm.append(float(thing.select('td')[4].string))\n",
    "                    _3pa.append(float(thing.select('td')[5].string))\n",
    "                    \n",
    "                    names.append(idk2[i].select('td')[1].string)\n",
    "                    _3pm.append(float(idk2[i].select('td')[4].string))\n",
    "                    _3pa.append(float(idk2[i].select('td')[5].string))\n",
    "                    i+=1\n",
    "                except:\n",
    "                    continue\n",
    "                    i+=1\n",
    "        else:\n",
    "            for thing in idk2:\n",
    "                try:    \n",
    "                    names.append(thing.select('td')[1].string)\n",
    "                    _3pm.append(float(thing.select('td')[4].string))\n",
    "                    _3pa.append(float(thing.select('td')[5].string))\n",
    "                    \n",
    "                    names.append(idk[i].select('td')[1].string)\n",
    "                    _3pm.append(float(idk[i].select('td')[4].string))\n",
    "                    _3pa.append(float(idk[i].select('td')[5].string))\n",
    "                    i+=1\n",
    "                except:\n",
    "                    continue\n",
    "                    i+=1\n",
    "            \n",
    "    D = {'Name':names, '_3pm':_3pm, '_3pa':_3pa}\n",
    "    df2 = pd.DataFrame(data=D)\n",
    "\n",
    "            \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESPN assists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assists_info (year):\n",
    "    \n",
    "    list_years = []\n",
    "    i = year\n",
    "    for num in range(0,1):\n",
    "        list_years.append(str(i))\n",
    "        i+=1\n",
    "        \n",
    "    \n",
    "    links = []\n",
    "    for thing in list_years:\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/assists/sort/avgPoints/year/'+thing)\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/assists/sort/avgPoints/year/'+thing+'/count/41')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/assists/sort/avgPoints/year/'+thing+'/count/81')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/assists/sort/avgPoints/year/'+thing+'/count/121')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/assists/sort/avgPoints/year/'+thing+'/count/161')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/assists/sort/avgPoints/year/'+thing+'/count/201')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/assists/sort/avgPoints/year/'+thing+'/count/241')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/assists/sort/avgPoints/year/'+thing+'/count/281')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/assists/sort/avgPoints/year/'+thing+'/count/321')\n",
    "    \n",
    "    \n",
    "    names = []\n",
    "    APG = []\n",
    "    AST_TO = []\n",
    "    for link in links:\n",
    "        #print(link)\n",
    "        page = requests.get(link)\n",
    "        soup = BS(page.content, 'html.parser')\n",
    "        idk=soup.select('tr[class^=\"oddrow\"]')\n",
    "        idk2=soup.select('tr[class^=\"evenrow\"]')\n",
    "        i = 0\n",
    "        if len(idk)>len(idk2):\n",
    "            for thing in idk:\n",
    "                try:    \n",
    "                    names.append(thing.select('td')[1].string)\n",
    "                    APG.append(float(thing.select('td')[4].string))\n",
    "                    AST_TO.append(float(thing.select('td')[7].string))\n",
    "                    \n",
    "                    names.append(idk2[i].select('td')[1].string)\n",
    "                    APG.append(float(idk2[i].select('td')[4].string))\n",
    "                    AST_TO.append(float(idk2[i].select('td')[7].string))\n",
    "                    i+=1\n",
    "                except:\n",
    "                    continue\n",
    "                    i+=1\n",
    "        else:\n",
    "            for thing in idk2:\n",
    "                try:    \n",
    "                    names.append(thing.select('td')[1].string)\n",
    "                    APG.append(float(thing.select('td')[4].string))\n",
    "                    AST_TO.append(float(thing.select('td')[7].string))\n",
    "                    \n",
    "                    names.append(idk[i].select('td')[1].string)\n",
    "                    APG.append(float(idk[i].select('td')[4].string))\n",
    "                    AST_TO.append(float(idk[i].select('td')[7].string))\n",
    "                    i+=1\n",
    "                except:\n",
    "                    continue\n",
    "                    i+=1\n",
    "            \n",
    "    D = {'Name':names, 'APG':APG, 'AST_TO':AST_TO}\n",
    "    df2 = pd.DataFrame(data=D)\n",
    "\n",
    "            \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESPN Steals info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steals_info (year):\n",
    "    \n",
    "    list_years = []\n",
    "    i = year\n",
    "    for num in range(0,1):\n",
    "        list_years.append(str(i))\n",
    "        i+=1\n",
    "        \n",
    "    \n",
    "    links = []\n",
    "    for thing in list_years:\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/steals/sort/avgPoints/year/'+thing)\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/steals/sort/avgPoints/year/'+thing+'/count/41')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/steals/sort/avgPoints/year/'+thing+'/count/81')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/steals/sort/avgPoints/year/'+thing+'/count/121')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/steals/sort/avgPoints/year/'+thing+'/count/161')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/steals/sort/avgPoints/year/'+thing+'/count/201')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/steals/sort/avgPoints/year/'+thing+'/count/241')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/steals/sort/avgPoints/year/'+thing+'/count/281')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/steals/sort/avgPoints/year/'+thing+'/count/321')\n",
    "    \n",
    "    \n",
    "    names = []\n",
    "    STPG = []\n",
    "    for link in links:\n",
    "        #print(link)\n",
    "        page = requests.get(link)\n",
    "        soup = BS(page.content, 'html.parser')\n",
    "        idk=soup.select('tr[class^=\"oddrow\"]')\n",
    "        idk2=soup.select('tr[class^=\"evenrow\"]')\n",
    "        i = 0\n",
    "        if len(idk)>len(idk2):\n",
    "            for thing in idk:\n",
    "                try:    \n",
    "                    names.append(thing.select('td')[1].string)\n",
    "                    STPG.append(float(thing.select('td')[4].string))\n",
    "                    \n",
    "                    names.append(idk2[i].select('td')[1].string)\n",
    "                    STPG.append(float(idk2[i].select('td')[4].string))\n",
    "                    i+=1\n",
    "                except:\n",
    "                    continue\n",
    "                    i+=1\n",
    "        else:\n",
    "            for thing in idk2:\n",
    "                try:    \n",
    "                    names.append(thing.select('td')[1].string)\n",
    "                    STPG.append(float(thing.select('td')[4].string))\n",
    "                    \n",
    "                    names.append(idk[i].select('td')[1].string)\n",
    "                    STPG.append(float(idk[i].select('td')[4].string))\n",
    "                    i+=1\n",
    "                except:\n",
    "                    continue\n",
    "                    i+=1\n",
    "            \n",
    "    D = {'Name':names, 'STPG':STPG}\n",
    "    df2 = pd.DataFrame(data=D)\n",
    "\n",
    "            \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESPN get blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blocks_info (year):\n",
    "    \n",
    "    list_years = []\n",
    "    i = year\n",
    "    for num in range(0,1):\n",
    "        list_years.append(str(i))\n",
    "        i+=1\n",
    "        \n",
    "    \n",
    "    links = []\n",
    "    for thing in list_years:\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/blocks/sort/avgPoints/year/'+thing)\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/blocks/sort/avgPoints/year/'+thing+'/count/41')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/blocks/sort/avgPoints/year/'+thing+'/count/81')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/blocks/sort/avgPoints/year/'+thing+'/count/121')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/blocks/sort/avgPoints/year/'+thing+'/count/161')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/blocks/sort/avgPoints/year/'+thing+'/count/201')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/blocks/sort/avgPoints/year/'+thing+'/count/241')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/blocks/sort/avgPoints/year/'+thing+'/count/281')\n",
    "        links.append('http://www.espn.com/mens-college-basketball/statistics/team/_/stat/blocks/sort/avgPoints/year/'+thing+'/count/321')\n",
    "    \n",
    "    \n",
    "    names = []\n",
    "    BLKPG = []\n",
    "    for link in links:\n",
    "        #print(link)\n",
    "        page = requests.get(link)\n",
    "        soup = BS(page.content, 'html.parser')\n",
    "        idk=soup.select('tr[class^=\"oddrow\"]')\n",
    "        idk2=soup.select('tr[class^=\"evenrow\"]')\n",
    "        i = 0\n",
    "        if len(idk)>len(idk2):\n",
    "            for thing in idk:\n",
    "                try:    \n",
    "                    names.append(thing.select('td')[1].string)\n",
    "                    BLKPG.append(float(thing.select('td')[5].string))\n",
    "                    \n",
    "                    names.append(idk2[i].select('td')[1].string)\n",
    "                    BLKPG.append(float(idk2[i].select('td')[5].string))\n",
    "                    i+=1\n",
    "                except:\n",
    "                    continue\n",
    "                    i+=1\n",
    "        else:\n",
    "            for thing in idk2:\n",
    "                try:    \n",
    "                    names.append(thing.select('td')[1].string)\n",
    "                    BLKPG.append(float(thing.select('td')[5].string))\n",
    "                    \n",
    "                    names.append(idk[i].select('td')[1].string)\n",
    "                    BLKPG.append(float(idk[i].select('td')[5].string))\n",
    "                    i+=1\n",
    "                except:\n",
    "                    continue\n",
    "                    i+=1\n",
    "            \n",
    "    D = {'Name':names, 'BLKPG':BLKPG}\n",
    "    df2 = pd.DataFrame(data=D)\n",
    "\n",
    "            \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything for ESPN - Merges everything also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_espn (year):\n",
    "    df3 = get_score_info (year)\n",
    "    df4 = get_rebound_info (year)\n",
    "    df5 = get_field_goal_info (year)\n",
    "    df6=get_3_point_info (year)\n",
    "    df7=get_assists_info (year)\n",
    "    df8=get_steals_info (year)\n",
    "    df9=get_blocks_info (year)\n",
    "    df2=pd.merge(df3,df4, how = 'inner', on = 'Name')\n",
    "    df2=pd.merge(df5,df2, how = 'inner', on = 'Name')\n",
    "    df2=pd.merge(df6,df2, how = 'inner', on = 'Name')\n",
    "    df2=pd.merge(df7,df2, how = 'inner', on = 'Name')\n",
    "    df2=pd.merge(df8,df2, how = 'inner', on = 'Name')\n",
    "    df2=pd.merge(df9,df2, how = 'inner', on = 'Name')\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging espn and sports reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to run this\n",
    "def find_missing_values (blah):\n",
    "    the_values = []\n",
    "    for thing in list(range(0,126)):\n",
    "        if thing in blah:\n",
    "            continue\n",
    "        else:\n",
    "            #print(thing)\n",
    "            the_values.append(thing)\n",
    "    return the_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#still working on this - dont use\n",
    "def add_to_df (name1, num,df, df2, newdf2):\n",
    "    maybe=df2[(df2['Name']==f'{name1}')]\n",
    "    maybe2=newdf2[(newdf2['index']==num)]\n",
    "    dict = {'first_team':list(maybe2['first_team'])[0],'second_team':list(maybe2['second_team'])[0],\n",
    "            'winner':list(maybe2['winner'])[0],\n",
    "            'point_difference':list(maybe2['point_difference'])[0],'result':list(maybe2['result'])[0],\n",
    "            'name':list(maybe2['name'])[0],\n",
    "            'team_rank':list(maybe2['team_rank'])[0],'win':list(maybe2['win'])[0],\n",
    "            'higher_or_lower_seed':list(maybe2['higher_or_lower_seed'])[0],\n",
    "            'index':list(maybe2['index'])[0],'year_x':list(maybe['year'])[0], 'Name': list(maybe['Name'])[0],\n",
    "            'PTS':list(maybe['PTS'])[0],'year_y':list(maybe['year'])[0],\n",
    "            'FG_perc':list(maybe['FG_perc'])[0],'_3p_perc':list(maybe['_3p_perc'])[0],\n",
    "            'FT_perc':list(maybe['FT_perc'])[0],'year_y':list(maybe['year'])[0],\n",
    "            'BLKPG':list(maybe['BLKPG'])[0],'STPG':list(maybe['STPG'])[0],\n",
    "            'APG':list(maybe['APG'])[0],'AST_TO':list(maybe['AST_TO'])[0],\n",
    "            '_3pm':list(maybe['_3pm'])[0],'_3pa':list(maybe['_3pa'])[0],\n",
    "            '_2pm':list(maybe['_2pm'])[0],'_2pa':list(maybe['_2pa'])[0],\n",
    "            '_2p_perc':list(maybe['_2p_perc'])[0],'ORPG':list(maybe['ORPG'])[0],\n",
    "            'DRPG':list(maybe['DRPG'])[0],'RPG':list(maybe['RPG'])[0],}\n",
    "    possibly2=df.append(dict, ignore_index=True)\n",
    "    return possibly2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making dictionary to reference sports reference and ESPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"Alabama-Birmingham\"] = \"UAB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"ETSU\"] = \"East Tennessee State\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"UNC\"] = \"North Carolina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"St. Joseph's\"] = \"Saint Joseph's\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"Pitt\"] = \"Pittsburgh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"UC-Irvine\"] = \"UC Irvine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"Cal State Fullerton\"] = \"CSU Fullerton\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"College of Charleston\"] = \"Charleston\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"Miami (FL)\"] = \"Miami\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"Loyola (IL)\"] = \"Loyola Chicago\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"Penn\"] = \"Pennsylvania\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"Mount St. Mary's\"] = \"Mt. St. Mary's\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"ETSU\"] = \"East Tennessee State\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"UC-Davis\"] = \"UC Davis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"Hawaii\"] = \"Hawai'i\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"Cal State Bakersfield\"] = \"CSU Bakersfield\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"Albany (NY)\"] = \"Albany\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"St. John's (NY)\"] = \"St. John's\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"Alabama-Birmingham\"] = \"UAB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"Detroit\"] = \"Detroit Mercy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"UCSB\"] = \"UC Santa Barbara\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"St. Peter's\"] = \"Saint Peter's\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"Cal State Northridge\"] = \"CSU Northridge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"Cal State Fullerton\"] = \"CSU Fullerton\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"Texas-Arlington\"] = \"UT Arlington\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"Texas A&M-Corpus Christi\"] = \"Texas A&M-CC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"Southeastern Louisiana\"] = \"SE Louisiana\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"McNeese State\"] = \"McNeese\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"Prairie View\"] = \"Prairie View A&M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"Nicholls State\"] = \"Nicholls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"San Jose State\"] = \"San José St\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"Louisiana-Monroe\"] = \"UL Monroe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"Saint Francis (PA)\"] = \"St. Francis (PA)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"LIU\"] = \"Long Island University\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESPN_sports_reference_dict[\"Southeast Missouri State\"] = \"SE Missouri St\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiles all functions from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def really_everything (year):\n",
    "    #getting sports reference stuff\n",
    "    newdf2=everything ('https://www.sports-reference.com/cbb/postseason/'+f'{year}'+'-ncaa.html')\n",
    "    the_year = []\n",
    "    #print('before the for loop')\n",
    "    for thing in newdf2['first_team']:\n",
    "        the_year.append(year)\n",
    "    newdf2['year']=the_year\n",
    "    #print('right before new loop')\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    #getting ESPN stuff\n",
    "    df2=merge_espn (year)\n",
    "    #print('finished espn')\n",
    "    \n",
    "    #merging\n",
    "    possibly2 = pd.merge(newdf2,df2, left_on = 'name', right_on = 'Name')\n",
    "    possibly2 = possibly2.sort_values(by ='index' )\n",
    "    the_values=find_missing_values (list(possibly2['index']))\n",
    "    for thing in the_values:\n",
    "        #print(thing)\n",
    "        the_name=list(newdf2[(newdf2['index']==thing)]['name'])[0]\n",
    "        ESPN_name=ESPN_sports_reference_dict[f\"{the_name}\"]\n",
    "        possibly2=add_to_df (ESPN_name, thing,possibly2, df2, newdf2)\n",
    "    \n",
    "    \n",
    "    other_team_seed = []\n",
    "    i = 0\n",
    "    for thing in list(possibly2['team_rank']):\n",
    "        if thing == list(possibly2['second_team'])[i]:\n",
    "            other_team_seed.append(list(possibly2['first_team'])[i])\n",
    "        elif thing == list(possibly2['first_team'])[i]:\n",
    "            other_team_seed.append(list(possibly2['second_team'])[i])\n",
    "        i+=1\n",
    "    #print('made it here')\n",
    "    possibly2['other_team_seed']=other_team_seed\n",
    "    #print('finished sports reference')\n",
    "    \n",
    "    \n",
    "    possibly2.drop(['first_team','second_team'], axis = 1, inplace = True)\n",
    "    possibly2.rename(columns={'team_rank':'team_seed'}, inplace = True)\n",
    "    possibly2 = possibly2.sort_values(by ='index' )\n",
    "\n",
    "        \n",
    "    return possibly2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grabbing the advanced stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_advanced_stats (year):\n",
    "    page = requests.get('https://www.sports-reference.com/cbb/seasons/'+f'{year}'+'-advanced-school-stats.html')\n",
    "    soup = BS(page.content, 'html.parser')\n",
    "    idk = soup.select('tbody')\n",
    "    \n",
    "    name_adv=[]\n",
    "    SRS_adv = []\n",
    "    SOS_adv = []\n",
    "    eFG_perc_adv = []\n",
    "    FTr_adv = []\n",
    "    \n",
    "    for thing in idk[0].select('tr'):\n",
    "        try:\n",
    "\n",
    "            #school name\n",
    "            name=thing.select('td[data-stat=\"school_name\"]')[0].select('a')[0].string\n",
    "            \n",
    "\n",
    "            #SRS\n",
    "            SRS=float(thing.select('td[data-stat=\"srs\"]')[0].string)\n",
    "            \n",
    "\n",
    "            #SOS\n",
    "            SOS = float(thing.select('td[data-stat=\"sos\"]')[0].string)\n",
    "            \n",
    "\n",
    "            #eFG%\n",
    "            eFG = float(thing.select('td[data-stat=\"efg_pct\"]')[0].string)\n",
    "            \n",
    "\n",
    "            #FTr\n",
    "            FTr = float(thing.select('td[data-stat=\"fta_per_fga_pct\"]')[0].string)\n",
    "            \n",
    "            \n",
    "            name_adv.append(name)\n",
    "            SRS_adv.append(SRS)\n",
    "            SOS_adv.append(SOS)\n",
    "            eFG_perc_adv.append(eFG)\n",
    "            FTr_adv.append(FTr)\n",
    "            \n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    the_year = []\n",
    "    for thing in FTr_adv:\n",
    "        the_year.append(year)\n",
    "    \n",
    "    D = {'name':name_adv,'SRS_adv':SRS_adv,'SOS_adv':SOS_adv,'eFG_perc_adv':eFG_perc_adv,'year_adv':the_year}\n",
    "    adv_stats = pd.DataFrame(data=D)\n",
    "    \n",
    "    return adv_stats\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making internal dictionary for sports reference to connect their march madness data and\n",
    "#commented out code is for finding the names that need a dictionary for merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df is all_data_not_advanced\n",
    "# team_names=list(df['name'].unique())\n",
    "# team_names = {'name':(team_names)}\n",
    "# team_names = pd.DataFrame(data=team_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adv_team_names=list(adv_stats['name'])\n",
    "# adv_team_names = {'name':(adv_team_names)}\n",
    "# adv_team_names = pd.DataFrame(data=adv_team_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please=pd.merge(adv_team_names,team_names, on = 'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_names=list(please['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need_dictionary_names = []\n",
    "# for name in list(team_names['name']):\n",
    "#     if name in merged_names:\n",
    "#         continue\n",
    "#     else:\n",
    "#         need_dictionary_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need_dictionary_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#march madness in the brackets and the adv stats name on the right side of the equal side\n",
    "sports_ref_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports_ref_dict[\"SMU\"]= \"Southern Methodist\"\n",
    "sports_ref_dict[\"USC\"]= \"Southern California\"\n",
    "sports_ref_dict[\"Pitt\"]= \"Pittsburgh\"\n",
    "sports_ref_dict[\"Penn\"]= \"Pennsylvania\"\n",
    "sports_ref_dict[\"LSU\"]= \"Louisiana State\"\n",
    "sports_ref_dict[\"UNC\"]= \"North Carolina\"\n",
    "sports_ref_dict[\"UNLV\"]= \"Nevada-Las Vegas\"\n",
    "sports_ref_dict[\"UTEP\"]= \"Texas-El Paso\"\n",
    "sports_ref_dict[\"NC State\"]= \"North Carolina State\"\n",
    "sports_ref_dict[\"VCU\"]= \"Virginia Commonwealth\"\n",
    "sports_ref_dict[\"St. Joseph's\"]= \"Saint Joseph's\"\n",
    "sports_ref_dict[\"TCU\"]= \"Texas Christian\"\n",
    "sports_ref_dict[\"BYU\"]= \"Brigham Young\"\n",
    "sports_ref_dict[\"UTSA\"]= \"Texas-San Antonio\"\n",
    "sports_ref_dict[\"UCSB\"]= \"UC-Santa Barbara\"\n",
    "sports_ref_dict[\"ETSU\"]= \"East Tennessee State\"\n",
    "sports_ref_dict[\"Saint Mary's\"]=\"Saint Mary's (CA)\"\n",
    "sports_ref_dict[\"UConn\"]=\"Connecticut\"\n",
    "sports_ref_dict[\"California\"]=\"University of California\"\n",
    "sports_ref_dict[\"Southern Miss\"]=\"Southern Mississippi\"\n",
    "sports_ref_dict[\"St. Peter's\"]=\"Saint Peter's\"\n",
    "sports_ref_dict[\"UMass\"]=\"Massachusetts\"\n",
    "sports_ref_dict[\"Long Beach State\"]=\"Cal State Long Beach\"\n",
    "sports_ref_dict[\"UCF\"]=\"Central Florida\"\n",
    "sports_ref_dict[\"UNC Greensboro\"]=\"North Carolina-Greensboro\"\n",
    "sports_ref_dict[\"LIU\"]=\"Long Island University\"\n",
    "sports_ref_dict[\"Ole Miss\"]=\"Mississippi\"\n",
    "sports_ref_dict[\"UIC\"]=\"Illinois-Chicago\"\n",
    "sports_ref_dict[\"Detroit\"]=\"Detroit Mercy\"\n",
    "sports_ref_dict[\"Central Connecticut\"]=\"Central Connecticut State\"\n",
    "sports_ref_dict[\"UNC Wilmington\"]=\"North Carolina-Wilmington\"\n",
    "sports_ref_dict[\"UNC Asheville\"]=\"North Carolina-Asheville\"\n",
    "sports_ref_dict[\"UMBC\"]=\"Maryland-Baltimore County\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for merging with sports reference adv data and uses created dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sr (df1,adv_stats,year):\n",
    "    merged_df=pd.merge(df1[(df1['year_x']==year)], adv_stats[(adv_stats['year_adv']==year)],\n",
    "                 how = 'inner', left_on='names_for_merging_sr', right_on = 'name')\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# addind in opponent data and subtraction of opponent data to adv_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass through the dataframe you want to add to and the column name\n",
    "#it will create a new column with the columnname_opponent\n",
    "def get_opponent_data (df, column_name):\n",
    "    first_data = []\n",
    "    second_data = []\n",
    "    i=0\n",
    "    x = 0\n",
    "    for thing in df[f'{column_name}']:\n",
    "        if i ==0:\n",
    "            first_data.append(df[f'{column_name}'].iloc[x+1])\n",
    "            i+=1\n",
    "            x+=1\n",
    "        elif i==1:\n",
    "            second_data.append(df[f'{column_name}'].iloc[x-1])\n",
    "            i=0\n",
    "            x+=1\n",
    "    \n",
    "    i=0\n",
    "    x=0\n",
    "    opponent_data = []\n",
    "    for thing in first_data+second_data:\n",
    "        if i==0:\n",
    "            opponent_data.append(first_data[x])\n",
    "            i+=1\n",
    "        elif i==1:\n",
    "            opponent_data.append(second_data[x])\n",
    "            x+=1\n",
    "            i=0\n",
    "    print('made it here')        \n",
    "    df[f'{column_name}'+'_opponent']=opponent_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtracted_stats  (df,column):\n",
    "    i = 0\n",
    "    subtracted = []\n",
    "    for thing in list(df[f'{column}']):\n",
    "        difference=list(df[f'{column}'])[i]-list(df[f'{column}'+'_opponent'])[i]\n",
    "        subtracted.append(difference)\n",
    "        i+=1\n",
    "    \n",
    "    df[f'{column}'+'_subtracted']=subtracted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert the rounds back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure at bottom to change number in function when reassigning the round_ to 0:number in dataframe\n",
    "def insert_rounds (df,column):\n",
    "    round_=[]\n",
    "    i=0\n",
    "    for thing in list(column):\n",
    "        if i== 62:\n",
    "            round_.append(6)\n",
    "            round_.append(6)\n",
    "            i=0\n",
    "        elif 0<=i<=7 or 15<=i<=22 or 30<=i<=37 or 45<=i<=52:\n",
    "            round_.append(1)\n",
    "            round_.append(1)\n",
    "            i+=1\n",
    "        elif 8<=i<=11 or 23<=i<=26 or 38<=i<=41 or 53<=i<=56:\n",
    "            round_.append(2)\n",
    "            round_.append(2)\n",
    "            i+=1\n",
    "        elif 12<=i<=13 or 27<=i<=28 or 42<=i<=43 or 57<=i<=58:\n",
    "            round_.append(3)\n",
    "            round_.append(3)\n",
    "            i+=1\n",
    "        elif i==14 or i==29 or i==44 or i==59:\n",
    "            round_.append(4)\n",
    "            round_.append(4)\n",
    "            i+=1\n",
    "        elif i == 60 or i == 61:\n",
    "            round_.append(5)\n",
    "            round_.append(5)\n",
    "            i+=1\n",
    "    round_ = round_[0:126]\n",
    "    return round_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Kenpom Ratings and wins/losses from regular season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kenpom_wins_losses (year):\n",
    "    page = requests.get('https://kenpom.com/index.php?y='+f'{year}')\n",
    "    soup = BS(page.content, 'html.parser')\n",
    "    idk = soup.select('tr')\n",
    "\n",
    "\n",
    "    names = []\n",
    "    wins_losses = []\n",
    "    kenpom_adjem = []\n",
    "    for thing in idk:\n",
    "        try:\n",
    "            names.append(thing.select('a[href^=\"team.php?team=\"]')[0].string)\n",
    "            wins_losses.append(thing.select('td[class=\"wl\"]')[0].text)\n",
    "            kenpom_adjem.append(float(thing.select('td')[4].text))          \n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    wins = []\n",
    "    losses = []\n",
    "    for thing in wins_losses:\n",
    "        i=0\n",
    "        for num in thing:\n",
    "            if num !='-':\n",
    "                i+=1\n",
    "            elif num =='-':\n",
    "                wins.append(float(thing[0:i]))\n",
    "                losses.append(float(thing[i+1::]))\n",
    "                break\n",
    "    year_kenpom = []\n",
    "    for thing in wins:\n",
    "        year_kenpom.append(int(year))\n",
    "            \n",
    "    D = {'name_ken':names,'wins':wins,'losses':losses,'year_kenpom':year_kenpom,'kenpom_adjem':kenpom_adjem}\n",
    "    kenpom_wins_losses = pd.DataFrame(data=D)\n",
    "    return kenpom_wins_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a dictionary for KenPom names to merge with all other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to figure out which names you need to make a dictionary for\n",
    "need_dictionary_names = []\n",
    "for thing in list(merged_df['Name']):\n",
    "    if thing in list(ken_pom['name_ken']):\n",
    "        continue\n",
    "    else:\n",
    "        need_dictionary_names.append(thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are the names you need to make a dictionary for\n",
    "set(need_dictionary_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name in the brackets and the kenpom name on the right side of the equal side\n",
    "kenpom_dict = {}\n",
    "kenpom_dict[\"Alabama State\"]=\"Alabama St.\"\n",
    "kenpom_dict[\"Alcorn State\"]=\"Alcorn St.\"\n",
    "kenpom_dict[\"Arkansas-Pine Bluff\"]=\"Arkansas Pine Bluff\"\n",
    "kenpom_dict[\"CSU Bakersfield\"]=\"Cal St. Bakersfield\"\n",
    "kenpom_dict[\"CSU Fullerton\"]=\"Cal St. Fullerton\"\n",
    "kenpom_dict[\"CSU Northridge\"]=\"Cal St. Northridge\"\n",
    "kenpom_dict[\"Detroit Mercy\"]=\"Detroit\"\n",
    "kenpom_dict[\"Florida International\"]=\"FIU\"\n",
    "kenpom_dict[\"Gardner-Webb\"]=\"Gardner Webb\"\n",
    "kenpom_dict[\"Hawai'i\"]=\"Hawaii\"\n",
    "kenpom_dict[\"Long Island University\"]=\"LIU\"\n",
    "kenpom_dict[\"Loyola (MD)\"]=\"Loyola MD\"\n",
    "kenpom_dict[\"McNeese\"]=\"McNeese St.\"\n",
    "kenpom_dict[\"Miami\"]=\"Miami FL\"\n",
    "kenpom_dict[\"Miami (OH)\"]=\"Miami OH\"\n",
    "kenpom_dict[\"Mt. St. Mary's\"]=\"Mount St. Mary's\"\n",
    "kenpom_dict[\"NC State\"]=\"N.C. State\"\n",
    "kenpom_dict[\"Nicholls\"]=\"Nicholls St.\"\n",
    "kenpom_dict[\"Ole Miss\"]=\"Mississippi\"\n",
    "kenpom_dict[\"Pennsylvania\"]=\"Penn\"\n",
    "kenpom_dict[\"SE Louisiana\"]=\"Southeastern Louisiana\"\n",
    "kenpom_dict[\"SE Missouri St\"]=\"Southeast Missouri St.\"\n",
    "kenpom_dict[\"San José St\"]=\"San Jose St.\"\n",
    "kenpom_dict[\"Texas A&M-CC\"]=\"Texas A&M Corpus Chris\"\n",
    "kenpom_dict[\"UConn\"]=\"Connecticut\"\n",
    "kenpom_dict[\"UIC\"]=\"Illinois Chicago\"\n",
    "kenpom_dict[\"UL Monroe\"]=\"Louisiana Monroe\"\n",
    "kenpom_dict[\"UMass\"]=\"Massachusetts\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a lot of the names I just needed to go from state --> st.\n",
    "#below code takes care of this in mass\n",
    "for name in need_dictionary_names:\n",
    "    if name in list(kenpom_dict.keys()):\n",
    "        continue\n",
    "    else:\n",
    "        kenpom_dict[f'{name}']=name[0:len(name)-3]+'.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flip the keys and values\n",
    "kenpom_dict2 = {y:x for x,y in kenpom_dict.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "kenpom_dict2[\"Troy St.\"]=\"Troy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "kenpom_dict2[\"Louisiana Lafayette\"]=\"Louisiana\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "kenpom_dict2[\"LIU Brooklyn\"]=\"Long Island University\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "kenpom_dict2[\"Arkansas Little Rock\"]=\"Little Rock\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "kenpom_dict2[\"College of Charleston\"]=\"Charleston\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for merging Ken_Pom with everything else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sr (df1,ken_pom,year):\n",
    "    merged_df=pd.merge(df1[(df1['year_x']==year)], ken_pom[(ken_pom['year_kenpom']==year)],\n",
    "                 how = 'inner', left_on='Name', right_on = 'names_for_merging_ken')\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection - using all the functions to collect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below gets regular stats from espn and regular seeding sports reference stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sports-reference.com/cbb/postseason/2003-ncaa.html\n"
     ]
    }
   ],
   "source": [
    "all_data_not_advanced=really_everything (2003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = []\n",
    "beg = 1986\n",
    "for num in range(1,35):\n",
    "    years.append(beg)\n",
    "    beg+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    data=really_everything(year)\n",
    "    all_data_not_advanced=all_data_not_advanced.append(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "index_ = []\n",
    "for thing in all_data_not_advanced['name']:\n",
    "    index_.append(i)\n",
    "    i+=1\n",
    "    \n",
    "all_data_not_advanced['index_everything']=index_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below gets advanced stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_stats=get_advanced_stats (2005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = []\n",
    "first = 1994\n",
    "for num in range(0,26):\n",
    "    years.append(first)\n",
    "    first+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    print(year)\n",
    "    adv_stat=get_advanced_stats (year)\n",
    "    adv_stats=adv_stats.append(adv_stat, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "at this point make sure the dictionary is good in \n",
    "\"making internal dictionary for sports reference to connect their march madness data\"\n",
    "Uncomment out the stuff to double check that the dictionary has everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below uses dictionary and adds in a column into the original sports reference ESPN stuff to merge on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_for_merging_sr = []\n",
    "for name in list(all_data_not_advanced['name']):\n",
    "    if name in sports_ref_dict.keys():\n",
    "        names_for_merging_sr.append(sports_ref_dict[f'{name}'])\n",
    "    else:\n",
    "        names_for_merging_sr.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_not_advanced['names_for_merging_sr']=names_for_merging_sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now below actually merges everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = []\n",
    "first = 1993\n",
    "for num in range(0,27):\n",
    "    years.append(first)\n",
    "    first+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for year in years:\n",
    "    if i==0:\n",
    "        merged_df=merge_sr (all_data_not_advanced,adv_stats,year)\n",
    "        merged_df = merged_df.sort_values(by ='index_everything' )\n",
    "        i=1\n",
    "    else:\n",
    "        merged=merge_sr (all_data_not_advanced,adv_stats,year)\n",
    "        merged_df=merged_df.append(merged, ignore_index=True)\n",
    "        merged_df = merged_df.sort_values(by ='index_everything' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets opponent and subtracted stuff for advanced stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['SRS_adv', 'SOS_adv', 'eFG_perc_adv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns:\n",
    "    get_opponent_data (merged_df, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for thing in columns:\n",
    "    subtracted_stats(merged_df,thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert round the game was played in into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#go to the function insert rounds and make sure the round_ = round_[0:3402]\n",
    "#right now it says 0:3402, but make sure the number after 0: is the length of your dataframe\n",
    "blah=insert_rounds (merged_df,merged_df['point_difference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['round']=blah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opponent_columns = ['BLKPG',\n",
    "       'STPG', 'APG', 'AST_TO', '_3pm', '_3pa', '_2pm', '_2pa', '_2p_perc',\n",
    "       'FG_perc', '_3p_perc', 'FT_perc', 'ORPG', 'DRPG', 'RPG',\n",
    "       'PTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in opponent_columns:\n",
    "    get_opponent_data (merged_df, f'{column}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for thing in opponent_columns:\n",
    "    subtracted_stats(merged_df,thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below is getting the kenpom stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ken_pom=get_kenpom_wins_losses (2005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = []\n",
    "first = 2003\n",
    "for num in range(0,17):\n",
    "    years.append(first)\n",
    "    first+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    KP=get_kenpom_wins_losses (year)\n",
    "    ken_pom=ken_pom.append(KP, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below inserts another column with a name to merge ken_pom stuff with everything else\n",
    "#Go to 'Making a dictionary for KenPom names to merge with all other data' to run code to make sure\n",
    "#you have all the names in the dictionary to merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_for_merging_ken = []\n",
    "for name in list(ken_pom['name_ken']):\n",
    "    if name in kenpom_dict2.keys():\n",
    "        names_for_merging_ken.append(kenpom_dict2[f'{name}'])\n",
    "    else:\n",
    "        names_for_merging_ken.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ken_pom['names_for_merging_ken']=names_for_merging_ken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below merges ken_pom with everything else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = []\n",
    "first = 2002\n",
    "for num in range(0,18):\n",
    "    years.append(first)\n",
    "    first+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for year in years:\n",
    "    if i==0:\n",
    "        merged_df1=merge_sr (merged_df,ken_pom,year)\n",
    "        merged_df1 = merged_df1.sort_values(by ='index_everything' )\n",
    "        i=1\n",
    "    else:\n",
    "        merged=merge_sr (merged_df,ken_pom,year)\n",
    "        merged_df1=merged_df1.append(merged, ignore_index=True)\n",
    "        merged_df1 = merged_df1.sort_values(by ='index_everything' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below gets opponent data and difference between team and opponent for ken_pom stuff and wins/losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opponent_columns = ['wins', 'losses', 'kenpom_adjem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in opponent_columns:\n",
    "    get_opponent_data (merged_df1, f'{column}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for thing in opponent_columns:\n",
    "    subtracted_stats(merged_df1,thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
